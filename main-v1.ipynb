{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!apt-get update &&    apt-get install -y   software-properties-common &&  add-apt-repository ppa:deadsnakes/ppa -y \n",
    "!apt-get update \n",
    "\n",
    "!apt-get install -y    python3.10    python3.10-venv    python3.10-distutils    python3-pip    wget    git    libgl1    libreoffice    fonts-noto-cjk    fonts-wqy-zenhei    fonts-wqy-microhei    ttf-mscorefonts-installer    fontconfig    libglib2.0-0    libxrender1    libsm6    libxext6    poppler-utils \\\n",
    "\n",
    "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!pip install -U \"magic-pdf[full]\"\n",
    "!pip install flask pyngrok\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/opendatalab/MinerU/raw/master/scripts/download_models_hf.py -O download_models_hf.py\n",
    "!python download_models_hf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/opendatalab/MinerU/raw/master/magic-pdf.template.json &&  cp magic-pdf.template.json /root/magic-pdf.json\n",
    "!sed -i 's|cpu|cuda|g' /root/magic-pdf.json\n",
    "!cat /root/magic-pdf.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T05:34:59.550Z",
     "iopub.execute_input": "2025-06-08T03:43:30.931715Z",
     "iopub.status.busy": "2025-06-08T03:43:30.931391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kaggle is now live at: NgrokTunnel: \"https://adfe-34-138-110-216.ngrok-free.app\" -> \"http://localhost:5000\"\n",
      "✅ Model loaded successfully (this is a placeholder).\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "!rm $(ls ./ ) -r\n",
    "\n",
    "\n",
    "import os\n",
    "from os.path import sep\n",
    "import fitz\n",
    "from PIL import Image\n",
    "from flask import Flask, request, jsonify ,send_file,Response\n",
    "from zipfile import ZipFile\n",
    "from io import  BytesIO\n",
    "from pyngrok import ngrok\n",
    "import traceback\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "from magic_pdf.data.data_reader_writer import (\n",
    "    FileBasedDataWriter,\n",
    ")\n",
    "from magic_pdf.data.dataset import ImageDataset\n",
    "from magic_pdf.model.doc_analyze_by_custom_model import doc_analyze,batch_doc_analyze\n",
    "from magic_pdf.operators.models import InferenceResult, PipeResult\n",
    "\n",
    "\n",
    "# --- 1. SETUP THE TUNNEL ---\n",
    "# Authenticate ngrok using the secret you stored\n",
    "user_secrets = UserSecretsClient()\n",
    "ngrok.set_auth_token(user_secrets.get_secret(\"NGROK_AUTH_TOKEN\"))\n",
    "\n",
    "# Open a tunnel to the Flask app port (we'll use 5000)\n",
    "public_url = ngrok.connect(5000)\n",
    "print(f\"✅ Kaggle is now live at: {public_url}\")\n",
    "\n",
    "\n",
    "# --- 2. LOAD YOUR HEAVY MODEL (DO THIS ONLY ONCE) ---\n",
    "# This is where you would load your model, weights, etc.\n",
    "# Example:\n",
    "# from your_module import load_model, predict_function\n",
    "# model = load_model('/kaggle/input/my-repo-name/models/best_model.pth')\n",
    "print(\"✅ Model loaded successfully (this is a placeholder).\")\n",
    "\n",
    "def detect_layout_miner_u_online(img_bytes: bytes, data: dict):\n",
    "\n",
    "\n",
    "    exam = data.get(\"exam\", \"\")\n",
    "    d_mode = data.get(\"display-mode\", \"\")\n",
    "    nr = \"nr\" + str(data.get(\"number\", 0)) + \"_\"\n",
    "    want = data.get(\"want\", \"md_content.md\")\n",
    "\n",
    "    key = exam + d_mode\n",
    "    f_dir = sep.join([\".\",\"results\",key])\n",
    "    os.makedirs(f_dir, exist_ok=True)\n",
    "    f_path = f\"{f_dir}{sep}{nr}{want}\"\n",
    "\n",
    "    md_image_dir  = f\"{f_dir}{sep}{nr}images\"\n",
    "    if not os.path.exists(f_path):\n",
    "        print(\"ocring ....\")\n",
    "        image_dir = str(os.path.basename(md_image_dir))\n",
    "\n",
    "        os.makedirs(md_image_dir, exist_ok=True)\n",
    "\n",
    "        image_writer, md_writer = FileBasedDataWriter(\n",
    "            md_image_dir\n",
    "        ), FileBasedDataWriter(f_dir)\n",
    "\n",
    "        lang = \"ch_server\"\n",
    "        ds = ImageDataset(img_bytes, lang=lang)\n",
    "\n",
    "        inf_res: InferenceResult = ds.apply(\n",
    "            doc_analyze,\n",
    "            ocr=True,\n",
    "            lang=lang,\n",
    "            show_log=True,\n",
    "        )\n",
    "\n",
    "        p5 = f\"{f_dir}{sep}{nr}draw5.png\"\n",
    "        inf_res.draw_model(p5)\n",
    "        pdf_to_png(p5)\n",
    "\n",
    "        pip_res: PipeResult = inf_res.pipe_ocr_mode(image_writer, lang=lang)\n",
    "\n",
    "\n",
    "        pip_res.dump_md(md_writer, f\"{nr}md_content.md\", image_dir)\n",
    "\n",
    "        p2 = f\"{f_dir}{sep}{nr}draw2.png\"\n",
    "        pip_res.draw_layout(p2)\n",
    "        pdf_to_png(p2)\n",
    "\n",
    "        p3 = f\"{f_dir}{sep}{nr}draw3.png\"\n",
    "        pip_res.draw_span(p3)\n",
    "        pdf_to_png(p3)\n",
    "\n",
    "        p4 = f\"{f_dir}{sep}{nr}draw4.png\"\n",
    "        pip_res.draw_line_sort(p4)\n",
    "        pdf_to_png(p4)\n",
    "    else:\n",
    "        print(\"using cached version\")\n",
    "\n",
    "    if want != \"md_content.md\":\n",
    "        return send_file(f_path, as_attachment=True)\n",
    "\n",
    "    file_paths = [f\"{md_image_dir}{sep}{f}\" for f in os.listdir(md_image_dir)]\n",
    "    file_paths.append(f_path)\n",
    "    memory_file = BytesIO()\n",
    "    with ZipFile(memory_file, 'w') as zf:\n",
    "        for file_path in file_paths:\n",
    "            zf.write(file_path, os.path.basename(file_path))\n",
    "    memory_file.seek(0)\n",
    "    return Response(memory_file.getvalue(), mimetype='application/zip',\n",
    "                     headers={'Content-Disposition': f'attachment;filename=md_content.zip'}\n",
    "                    )\n",
    "\n",
    "\n",
    "def pdf_to_png(pdf_path):\n",
    "\n",
    "    dpi = 150\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(0)\n",
    "    pix = page.get_pixmap(dpi=dpi)\n",
    "    mode = \"RGBA\" if pix.alpha else \"RGB\"\n",
    "    img = Image.frombytes(mode, (pix.width, pix.height), pix.samples)\n",
    "    doc.close()\n",
    "    img.save(pdf_path, \"png\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. CREATE THE FLASK APP ---\n",
    "app = Flask(__name__)\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def say_hallo():\n",
    "    return jsonify({\"message\":\"hallo zakir\"})\n",
    "    \n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    \"\"\"The main endpoint for your GUI to call.\"\"\"\n",
    "    try:\n",
    "        image_file = request.files['image']\n",
    "        image_bytes = image_file.read()\n",
    "        print(request.form)\n",
    "        return  detect_layout_miner_u_online(image_bytes,request.form)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        print(f\"Error: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/predict/advance\", methods=[\"POST\"])\n",
    "def predict_advance():\n",
    "    \"\"\"The main endpoint for your GUI to call.\"\"\"\n",
    "    try:\n",
    "        image_file = request.files['image']\n",
    "        image_group_bytes :bytes = image_file.read()\n",
    "        fo = request.form\n",
    "        print(fo)\n",
    "        sep = fo.get(\"seperator\").encode(\"latin\")\n",
    "        idx = fo.get(\"idx\")\n",
    "        data_sets = []\n",
    "        lang = \"ch_server\"\n",
    "        for im_bytes in image_group_bytes.split(sep):\n",
    "            if  im_bytes:\n",
    "                data_sets.append( ImageDataset(im_bytes, lang=lang))\n",
    "\n",
    "        inf_res_list : list[InferenceResult] = batch_doc_analyze(\n",
    "            data_sets,\n",
    "            parse_method=\"ocr\" ,\n",
    "            lang=lang,\n",
    "            show_log=True,\n",
    "        )\n",
    "        image_dir = \"./temp\"\n",
    "        os.makedirs(image_dir,exist_ok=True)\n",
    "        image_writer = FileBasedDataWriter( image_dir)\n",
    "        final_res = {}\n",
    "        for i,inf_res in enumerate(inf_res_list):\n",
    "            pip_res: PipeResult = inf_res.pipe_ocr_mode(image_writer,lang=lang)\n",
    "            cont = pip_res.get_content_list(image_dir)\n",
    "            id = idx[i]\n",
    "            final_res[id] = cont\n",
    "        return jsonify(final_res) , 200\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        print(f\"Error: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# This will run the Flask app and keep the notebook cell running.\n",
    "app.run(port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
